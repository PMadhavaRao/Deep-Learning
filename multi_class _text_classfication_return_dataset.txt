#6.Build a Deep Neural Network for multi class text classification using Reuters dataset

import tensorflow as tf
from tensorflow.keras.datasets import reuters
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, LSTM
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
# Load the Reuters dataset
(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)
# Preprocess the data
maxlen = 500 # Maximum sequence length
train_data = pad_sequences(train_data, maxlen=maxlen)
test_data = pad_sequences(test_data, maxlen=maxlen)
# One-hot encode the labels
num_classes = len(set(train_labels))
train_labels = to_categorical(train_labels, num_classes)
test_labels = to_categorical(test_labels, num_classes)
# Define the model architecture
model = Sequential()
model.add(Embedding(10000, 128, input_length=maxlen))
model.add(LSTM(128))
model.add(Dense(num_classes, activation='softmax'))
# Compile the model
model.compile(optimizer='adam',
loss='categorical_crossentropy',
metrics=['accuracy'])
# Train the model
history = model.fit(train_data, train_labels,
epochs=3,
batch_size=128,
validation_split=0.2)
# Evaluate the model
test_loss, test_acc = model.evaluate(test_data, test_labels)
print('Test accuracy:', test_acc)

import matplotlib.pyplot as plt
# Get training and validation loss
train_loss = history.history['loss']
val_loss = history.history['val_loss']
# Get training and validation accuracy
train_acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
# Plot loss
plt.figure(figsize=(10, 5))
plt.plot(train_loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
# Plot accuracy
plt.figure(figsize=(10, 5))
plt.plot(train_acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()


import numpy as np
import seaborn as sns
from sklearn.metrics import confusion_matrix
# Get predicted probabilities for each class
predicted_probs = model.predict(test_data)
# Convert probabilities to class labels
predicted_labels = np.argmax(predicted_probs, axis=1)
# Convert one-hot encoded labels back to categorical labels
test_labels_cat = np.argmax(test_labels, axis=1)
# Compute confusion matrix
conf_matrix = confusion_matrix(test_labels_cat, predicted_labels)
# Plot heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()